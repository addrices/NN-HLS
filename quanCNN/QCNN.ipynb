{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络并读取\n",
    "\n",
    "从事先训练好的网络中读取参数，并做量化操作。\n",
    "其中的onet作为原来没有量化的网络，而net会被量化成8bit的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net\n",
      "Size (MB): 0.071677\n",
      "Size (MB): 0.254867\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import  optim\n",
    "from torchvision import transforms\n",
    "from torch.quantization import QuantStub, DeQuantStub,QConfig\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch.quantization\n",
    "import time\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                nn.Conv2d(1,16,kernel_size=3), # 16, 26 ,26\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(16,32,kernel_size=3),# 32, 24, 24\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2)) # 32,12,12\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "                nn.Conv2d(32,64,kernel_size=3), # 64,10,10\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2))  # 64, 5,5\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "                nn.Conv2d(64,64,kernel_size=3), # 64,3,3\n",
    "                #nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3,stride=3))  # 64,1,1\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(64,32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(32,10))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.quant(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "# 预处理=>将各种预处理组合在一起\n",
    "data_tf = transforms.Compose(\n",
    "                [transforms.ToTensor(),\n",
    "                 transforms.Normalize([0.5],[0.5])])\n",
    " \n",
    "train_set = mnist.MNIST('./data',train=True,transform=data_tf,download=True)\n",
    "test_set = mnist.MNIST('./data',train=False,transform=data_tf,download=True)\n",
    " \n",
    "train_data = DataLoader(train_set,batch_size=1,shuffle=True)\n",
    "test_data = DataLoader(test_set,batch_size=1,shuffle=False)\n",
    "\n",
    "onet = CNN()\n",
    "net = CNN()\n",
    "net.load_state_dict(torch.load(\"./CNNnet.pt\"))\n",
    "onet.load_state_dict(torch.load(\"./CNNnet.pt\"))\n",
    "print(\"net\")\n",
    "\n",
    "my_qconfig = QConfig(activation= torch.quantization.default_observer.with_args(dtype=torch.quint8), weight=torch.quantization.default_observer.with_args(dtype=torch.qint8))\n",
    "net.qconfig = torch.quantization.default_qconfig\n",
    "\n",
    "torch.quantization.prepare(net, inplace=True)\n",
    "torch.quantization.convert(net, inplace=True)\n",
    "\n",
    "print_size_of_model(net)\n",
    "print_size_of_model(onet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察网络结构\n",
    "查看网络中各层的参数列表可以看到网络的组成，我们将量化后的参数提取出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====quant NN composition=====\n",
      "quant.scale\n",
      "quant.zero_point\n",
      "layer1.0.weight\n",
      "layer1.0.bias\n",
      "layer1.0.scale\n",
      "layer1.0.zero_point\n",
      "layer2.0.weight\n",
      "layer2.0.bias\n",
      "layer2.0.scale\n",
      "layer2.0.zero_point\n",
      "layer3.0.weight\n",
      "layer3.0.bias\n",
      "layer3.0.scale\n",
      "layer3.0.zero_point\n",
      "layer4.0.weight\n",
      "layer4.0.bias\n",
      "layer4.0.scale\n",
      "layer4.0.zero_point\n",
      "fc.0.scale\n",
      "fc.0.zero_point\n",
      "fc.0._packed_params.dtype\n",
      "fc.0._packed_params._packed_params\n",
      "fc.2.scale\n",
      "fc.2.zero_point\n",
      "fc.2._packed_params.dtype\n",
      "fc.2._packed_params._packed_params\n",
      "\n",
      "=====NN composition=====\n",
      "layer1.0.weight\n",
      "layer1.0.bias\n",
      "layer2.0.weight\n",
      "layer2.0.bias\n",
      "layer3.0.weight\n",
      "layer3.0.bias\n",
      "layer4.0.weight\n",
      "layer4.0.bias\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.2.weight\n",
      "fc.2.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"=====quant NN composition=====\")\n",
    "for name in net.state_dict():\n",
    "    print(name)\n",
    "\n",
    "print(\"\\n=====NN composition=====\")\n",
    "for name in onet.state_dict():\n",
    "    print(name)\n",
    "    \n",
    "qweight1 = net.state_dict()['layer1.0.weight']\n",
    "oweight1 = onet.state_dict()['layer1.0.weight']\n",
    "\n",
    "qweight2 = net.state_dict()['layer2.0.weight']\n",
    "oweight2 = onet.state_dict()['layer2.0.weight']\n",
    "\n",
    "qweight3 = net.state_dict()['layer3.0.weight']\n",
    "oweight3 = onet.state_dict()['layer3.0.weight']\n",
    "\n",
    "qweight4 = net.state_dict()['layer4.0.weight']\n",
    "oweight4 = onet.state_dict()['layer4.0.weight']\n",
    "\n",
    "qbias1 = net.state_dict()['layer1.0.bias']\n",
    "obias1 = onet.state_dict()['layer1.0.bias']\n",
    "\n",
    "qbias2 = net.state_dict()['layer2.0.bias']\n",
    "obias2 = onet.state_dict()['layer2.0.bias']\n",
    "\n",
    "qbias3 = net.state_dict()['layer3.0.bias']\n",
    "obias3 = onet.state_dict()['layer3.0.bias']\n",
    "\n",
    "qbias4 = net.state_dict()['layer4.0.bias']\n",
    "obias4 = onet.state_dict()['layer4.0.bias']\n",
    "\n",
    "qfcweight1 = net.state_dict()['fc.0._packed_params._packed_params'][0]\n",
    "ofcweight1 = onet.state_dict()['fc.0.weight']\n",
    "\n",
    "qfcweight2 = net.state_dict()['fc.2._packed_params._packed_params'][0]\n",
    "ofcweight2 = onet.state_dict()['fc.2.weight']\n",
    "\n",
    "qfcbias1 = net.state_dict()['fc.0._packed_params._packed_params'][1]\n",
    "ofcbias1 = onet.state_dict()['fc.0.bias']\n",
    "\n",
    "qfcbias2 = net.state_dict()['fc.0._packed_params._packed_params'][1]\n",
    "ofcbias2 = onet.state_dict()['fc.2.bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取量化信息\n",
    "我们将网络中的每一层的zero_point和scale值取出来，并向下取整到2的幂次。进行重新量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qweight1 0 193.4951654222813\n",
      "qweight2 0 455.6926789416391\n",
      "qweight3 0 567.5108962261097\n",
      "qweight4 0 484.9417163364051\n",
      "qfcweight1 0 296.82317966874973\n",
      "qfcbias1 0 183.76869356878268\n"
     ]
    }
   ],
   "source": [
    "print(\"qweight1\",qweight1.q_zero_point(),1/qweight1.q_scale())\n",
    "print(\"qweight2\",qweight2.q_zero_point(),1/qweight2.q_scale())\n",
    "print(\"qweight3\",qweight3.q_zero_point(),1/qweight3.q_scale())\n",
    "print(\"qweight4\",qweight4.q_zero_point(),1/qweight4.q_scale())\n",
    "print(\"qfcweight1\",qfcweight1.q_zero_point(),1/qfcweight1.q_scale())\n",
    "print(\"qfcbias1\",qfcweight2.q_zero_point(),1/qfcweight2.q_scale())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oweight1 = oweight1*128\n",
    "obias1 = obias1*128\n",
    "\n",
    "oweight2 = oweight2*256\n",
    "obias2 = obias2*256\n",
    "\n",
    "oweight3 = oweight3*512\n",
    "obias3 = obias3*512\n",
    "\n",
    "oweight4 = oweight4*256\n",
    "obias4 = obias4*256\n",
    "\n",
    "ofcweight1 = ofcweight1*256\n",
    "ofcbias1 = ofcbias1*256\n",
    "\n",
    "ofcweight2 = ofcweight2*128\n",
    "ofcbias2 = ofcbias2*128\n",
    "\n",
    "oweight1 = torch.round(oweight1)\n",
    "oweight2 = torch.round(oweight2)\n",
    "oweight3 = torch.round(oweight3)\n",
    "oweight4 = torch.round(oweight4)\n",
    "obias1 = torch.round(obias1)\n",
    "obias2 = torch.round(obias2)\n",
    "obias3 = torch.round(obias3)\n",
    "obias4 = torch.round(obias4)\n",
    "\n",
    "ofcweight1 = torch.round(ofcweight1)\n",
    "ofcweight2 = torch.round(ofcweight2)\n",
    "ofcbias1 = torch.round(ofcbias1)\n",
    "ofcbias2 = torch.round(ofcbias2)\n",
    "\n",
    "\n",
    "oweight1 = oweight1.to(torch.int16)\n",
    "oweight2 = oweight2.to(torch.int16)\n",
    "oweight3 = oweight3.to(torch.int16)\n",
    "oweight4 = oweight4.to(torch.int16)\n",
    "obias1 = obias1.to(torch.int16)\n",
    "obias2 = obias2.to(torch.int16)\n",
    "obias3 = obias3.to(torch.int16)\n",
    "obias4 = obias4.to(torch.int16)\n",
    "\n",
    "ofcweight1 = ofcweight1.to(torch.int16)\n",
    "ofcweight2 = ofcweight2.to(torch.int16)\n",
    "ofcbias1 = ofcbias1.to(torch.int16)\n",
    "ofcbias2 = ofcbias2.to(torch.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;\n",
    "for img , label in train_data:\n",
    "    if (i < 1):\n",
    "        #print(img)\n",
    "        #img = img.reshape(img.size(0),-1)\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        img = img.view(1,28,28)\n",
    "        for m in range(28):\n",
    "            for n in range(28):\n",
    "                if(img[0][m][n].item() < 0.5):\n",
    "                    img[0][m][n] = 0\n",
    "                else:\n",
    "                    img[0][m][n] = 1\n",
    "        i = i+1\n",
    "#         print(img)\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比量化后的网络和之前的网络的精度对比\n",
    "将测试集输入给被8bit量化的网络中运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k  9889  j  8447  i  10000\n"
     ]
    }
   ],
   "source": [
    "#quantized net\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "for img , label in test_data:\n",
    "        #print(img)\n",
    "        #img = img.reshape(img.size(0),-1)\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        start =  time.time()\n",
    "        out = net(img)\n",
    "        out1 = onet(img)\n",
    "\n",
    "        _ , pred = out.max(1)\n",
    "        _ , pred1 = out1.max(1)\n",
    "        if(pred1 == label):\n",
    "            k = k + 1\n",
    "        if(pred == label):\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "print(\"k \",k,\" j \",j,\" i \",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存权重信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_4D(FileName,P_tensor):\n",
    "    file = open(FileName,'w',encoding = 'utf-8')\n",
    "    print(P_tensor.size)\n",
    "    for i in range(P_tensor.size(0)):\n",
    "        file.write('{')\n",
    "        for j in range(P_tensor.size(1)):\n",
    "            file.write('{')\n",
    "            for k in range(P_tensor.size(2)):\n",
    "                file.write('{')\n",
    "                for l in range(P_tensor.size(3)):\n",
    "                    file.write(str(P_tensor[i][j][k][l].item()))\n",
    "                    if(l != P_tensor.size(3)-1):\n",
    "                        file.write(',')\n",
    "                file.write('}')\n",
    "                if(k != P_tensor.size(2)-1):\n",
    "                    file.write(',')\n",
    "            file.write('}')\n",
    "            if(j != P_tensor.size(1)-1):\n",
    "                file.write(',')\n",
    "        file.write('}')\n",
    "        if(i != P_tensor.size(0)-1):\n",
    "            file.write(',\\n')\n",
    "    file.write('}')\n",
    "    file.close()\n",
    "    \n",
    "def save_1D(FileName,P_tensor):\n",
    "    file = open(FileName,'w',encoding = 'utf-8')\n",
    "\n",
    "    file.write('{')\n",
    "    for i in range(P_tensor.size(0)):\n",
    "        file.write(str(P_tensor[i].item()))\n",
    "        if(i != P_tensor.size(0)-1):\n",
    "            file.write(',')\n",
    "    file.write('}')\n",
    "    file.close()\n",
    "    \n",
    "def save_2D(FileName,P_tensor):\n",
    "    file = open(FileName,'w',encoding = 'utf-8')\n",
    "\n",
    "    print(ofcweight1.size())\n",
    "    file.write('{')\n",
    "    for i in range(P_tensor.size(0)):\n",
    "        file.write('{')\n",
    "        for j in range(P_tensor.size(1)):\n",
    "            file.write(str(P_tensor[i][j].item()))\n",
    "            if(j != P_tensor.size(1)-1):\n",
    "                file.write(',')\n",
    "        file.write('}')\n",
    "        if (i != P_tensor.size(0)-1):\n",
    "            file.write(',\\n')\n",
    "    file.write('}')\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "def save_3D(FileName,P_tensor):\n",
    "    file = open(FileName,'w',encoding = 'utf-8')\n",
    "    file.write('{')\n",
    "    for i in range(P_tensor.size(1)):\n",
    "        file.write('{')\n",
    "        for j in range(P_tensor.size(2)):\n",
    "            file.write('{')\n",
    "            for k in range(P_tensor.size(0)):\n",
    "                file.write(str(P_tensor[k][i][j].item()))\n",
    "                if(k != P_tensor.size(0)-1):\n",
    "                    file.write(',')\n",
    "            file.write('}')\n",
    "            if(j != P_tensor.size(2)-1):\n",
    "                file.write(',\\n')\n",
    "        file.write('}')\n",
    "        if(i != P_tensor.size(1)-1):\n",
    "            file.write(',\\n')\n",
    "    file.write('}')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x7ff19c78ee10>\n",
      "<built-in method size of Tensor object at 0x7ff19c78e6c0>\n",
      "<built-in method size of Tensor object at 0x7ff19c78eab0>\n",
      "<built-in method size of Tensor object at 0x7ff19c78e7e0>\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "np.save(\"./fpga/oweight1\",  oweight1)\n",
    "np.save(\"./fpga/oweight2\",  oweight2)\n",
    "np.save(\"./fpga/oweight3\",  oweight3)\n",
    "np.save(\"./fpga/oweight4\",  oweight4)\n",
    "np.save(\"./fpga/obias1\",  obias1)\n",
    "np.save(\"./fpga/obias2\",  obias2)\n",
    "np.save(\"./fpga/obias3\",  obias3)\n",
    "np.save(\"./fpga/obias4\",  obias4)\n",
    "np.save(\"./fpga/ofcweight1\",  ofcweight1)\n",
    "np.save(\"./fpga/ofcweight2\",  ofcweight2)\n",
    "np.save(\"./fpga/ofcbias1\",  ofcbias1)\n",
    "np.save(\"./fpga/ofcbias2\",  ofcbias2)\n",
    "save_4D('Cw1.txt',oweight1)\n",
    "save_4D('Cw2.txt',oweight2)\n",
    "save_4D('Cw3.txt',oweight3)\n",
    "save_4D('Cw4.txt',oweight4)\n",
    "save_1D('Cb1.txt',obias1)\n",
    "save_1D('Cb2.txt',obias2)\n",
    "save_1D('Cb3.txt',obias3)\n",
    "save_1D('Cb4.txt',obias4)\n",
    "save_1D('Cfcb1.txt',ofcbias1)\n",
    "save_1D('Cfcb2.txt',ofcbias2)\n",
    "save_2D('Cfcw1.txt',ofcweight1)\n",
    "save_2D('Cfcw2.txt',ofcweight2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试数据到片上\n",
    "将MNIST数据转为整数形式存放，之后可以放置到PYNQ板子上进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.empty([10000,28,28], dtype = int) \n",
    "y = np.empty([10000,1], dtype = int) \n",
    "i = 0\n",
    "for img , label in test_data:\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        img = torch.round(img)+1\n",
    "        x[i] = img\n",
    "        y[i] = label\n",
    "        i = i+1\n",
    "np.save(\"img.npy\",x)\n",
    "np.save(\"label.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
